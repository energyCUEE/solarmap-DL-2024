{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM demo for solar irradiance forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Natanon Tongamrak*\n",
    "\n",
    "This is a demo of LightGBM presented in our manuscript `Developing a Thailand solar irradiance map using Himawari-8 satellite imageries and deep learning models'. You can browse to each of the following topics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Data Processing](#data-processing)\n",
    "- [Model Training](#model-training)\n",
    "- [Inference on test dataset](#run-the-model-on-test-set)\n",
    "- [Performance evaluation](#performance-evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib \n",
    "import lightgbm \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data from [Google drive](https://drive.google.com/drive/folders/1vsWaPqMnBp1Whd2GhcbVOdFj4JofFQ-M?usp=sharing) and import them for trainin, testing, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"dataset/preprocessed_data/train_data.csv\", parse_dates=['Datetime'])\n",
    "val_df   = pd.read_csv(\"dataset/preprocessed_data/val_data.csv\", parse_dates=['Datetime'])\n",
    "test_df  = pd.read_csv(\"dataset/preprocessed_data/test_data.csv\", parse_dates=['Datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imported data contains the results of a trained LGBM model. These results can be discarded if you wish to explore a new experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create lag features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the features from previous time stamp such that the model can learn the temporal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_features(full_df):\n",
    "    # Create an empty DataFrame to store the lagged features\n",
    "    lagged_features_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each site\n",
    "    for site in full_df['sitename'].unique():\n",
    "        site_df = full_df[full_df['sitename'] == site].copy()\n",
    "        site_df.set_index('Datetime', inplace=True)\n",
    "        \n",
    "        for lag in [1, 2, 3, 4]:\n",
    "            # Create lagged features for 'CI'\n",
    "            site_df[f'CI_lagged_{lag*15}'] = site_df['CI'].shift(periods=lag, freq='15min')\n",
    "            \n",
    "            # Create lagged features for 'R'\n",
    "            site_df[f'R_lagged_{lag*15}'] = site_df['R'].shift(periods=lag, freq='15min')\n",
    "        \n",
    "        site_df = site_df.reset_index()\n",
    "        lagged_features_df = pd.concat([lagged_features_df, site_df], ignore_index=True)\n",
    "\n",
    "    # Drop rows with NaN values created due to lagging\n",
    "    # lagged_features_df.dropna(inplace=True)\n",
    "\n",
    "    # Reset index of the final DataFrame\n",
    "    lagged_features_df.reset_index(drop=True, inplace=True)\n",
    "    return lagged_features_df\n",
    "\n",
    "train_df = create_lagged_features(train_df)\n",
    "val_df   = create_lagged_features(val_df)\n",
    "test_df  = create_lagged_features(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df = train_df.drop(columns=[f'R_lagged_{min}' for min in [15, 30, 45, 60]]+[f'CI_lagged_{min}' for min in [15, 30, 45, 60]]+['I_LGBM'])\n",
    "final_val_df   = val_df.drop(columns=[f'R_lagged_{min}' for min in [15, 30, 45, 60]]  +[f'CI_lagged_{min}' for min in [15, 30, 45, 60]]+['I_LGBM'])\n",
    "final_test_df  = test_df.drop(columns=[f'R_lagged_{min}' for min in [15, 30, 45, 60]] +[f'CI_lagged_{min}' for min in [15, 30, 45, 60]]+['I_LGBM'])\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "val_df   = val_df.dropna()\n",
    "test_df  = test_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select path to save the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_result = \"results_LightGBM\" # You can change the directory to the path that you want to save the result\n",
    "os.makedirs(path_to_save_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the types of input features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = \"I_wo_nwp_wo_latlong\" \n",
    "\n",
    "if feat_list == \"all\":\n",
    "\n",
    "    features_list= ['Iclr', \n",
    "                    'R', \n",
    "                    'CI',\n",
    "                    'R_lagged_15', \n",
    "                    'CI_lagged_15',\n",
    "                    'R_lagged_30', \n",
    "                    'CI_lagged_30', \n",
    "                    'R_lagged_45', \n",
    "                    'CI_lagged_45', \n",
    "                    'R_lagged_60', \n",
    "                    'CI_lagged_60', \n",
    "                    'hour_encode1', \n",
    "                    'latt', 'long',\n",
    "                    'day', 'month',\n",
    "                    'Inwp', 'Tnwp'\n",
    "                    ]\n",
    "elif feat_list == \"I_wo_nwp\":\n",
    "\n",
    "    features_list= ['Iclr', \n",
    "                    'R', \n",
    "                    'CI',\n",
    "                    'R_lagged_15', \n",
    "                    'CI_lagged_15',\n",
    "                    'R_lagged_30', \n",
    "                    'CI_lagged_30', \n",
    "                    'R_lagged_45', \n",
    "                    'CI_lagged_45', \n",
    "                    'R_lagged_60', \n",
    "                    'CI_lagged_60', \n",
    "                    'hour_encode1', \n",
    "                    'latt', 'long',\n",
    "                    'day', 'month'\n",
    "                    ]\n",
    "    \n",
    "elif feat_list == \"I_wo_nwp_wo_latlong\":\n",
    "\n",
    "    features_list= ['Iclr', \n",
    "                    'R', \n",
    "                    'CI',\n",
    "                    'R_lagged_15', \n",
    "                    'CI_lagged_15',\n",
    "                    'R_lagged_30', \n",
    "                    'CI_lagged_30', \n",
    "                    'R_lagged_45', \n",
    "                    'CI_lagged_45', \n",
    "                    'R_lagged_60', \n",
    "                    'CI_lagged_60', \n",
    "                    'hour_encode1',  \n",
    "                    'day', 'month'\n",
    "                    ]\n",
    "    \n",
    "target_col = ['I']\n",
    "\n",
    "X_train = train_df[features_list][train_df['is_target']]\n",
    "X_val = val_df[features_list][val_df['is_target']]\n",
    "X_test = test_df[features_list][test_df['is_target']]\n",
    "\n",
    "y_train = train_df[target_col][train_df['is_target']]\n",
    "y_val = val_df[target_col][val_df['is_target']]\n",
    "y_test = test_df[target_col][test_df['is_target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter setting and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 200,\n",
    "    'min_child_samples':100,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators':500,\n",
    "    'max_depth' : 15,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "model = lightgbm.LGBMRegressor(**params)\n",
    "\n",
    "model.fit(X_train, y_train) \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "eval_df = test_df[['sitename', 'Datetime','hour', 'I']][test_df['is_target']]\n",
    "eval_df['Ihat'] = y_pred\n",
    "eval_df['Date'] = pd.to_datetime(test_df['Datetime'].dt.date)\n",
    "eval_df = eval_df[eval_df['hour'].isin([hour for hour in range(7,18)])]\n",
    "\n",
    "\n",
    "overall_mae  = mean_absolute_error(eval_df['I'], eval_df['Ihat'])\n",
    "overall_rmse = mean_squared_error(eval_df['I'], eval_df['Ihat'], squared=False)\n",
    "overall_mbe  = np.mean(eval_df['Ihat']-eval_df['I'])\n",
    "\n",
    "print(overall_mae, overall_rmse, overall_mbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['I_LGBM'] = model.predict(train_df[features_list])\n",
    "val_df['I_LGBM']   = model.predict(val_df[features_list])\n",
    "test_df['I_LGBM']  = model.predict(test_df[features_list])\n",
    "\n",
    "train_df['I_LGBM'] = train_df['I_LGBM'].apply(lambda x: max(x, 0))\n",
    "val_df['I_LGBM']   = val_df['I_LGBM'].apply(lambda x: max(x, 0))\n",
    "test_df['I_LGBM']  = test_df['I_LGBM'].apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate MAE, RMSE, and MBE\n",
    "def calculate_metrics(df):\n",
    "    # Filter the DataFrame to include only the hours from 07:00 to 17:00\n",
    "    filtered_df = df[df['Datetime'].dt.hour.isin([7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17])]\n",
    "    \n",
    "    mae = np.mean(np.abs(filtered_df['I'] - filtered_df['I_LGBM']))\n",
    "    rmse = np.sqrt(np.mean((filtered_df['I'] - filtered_df['I_LGBM'])**2))\n",
    "    mbe = np.mean(filtered_df['I_LGBM'] - filtered_df['I'])\n",
    "    return pd.Series({'MAE': mae, 'RMSE': rmse, 'MBE': mbe})\n",
    "\n",
    "# Ensure 'Datetime' is a datetime type and add 'hour' column\n",
    "test_df['Datetime'] = pd.to_datetime(test_df['Datetime'])\n",
    "test_df['hour'] = test_df['Datetime'].dt.hour\n",
    "\n",
    "# Create the 'kavg_condition' column based on 'average_k'\n",
    "bins = [0, 0.6, 0.9, float('inf')]\n",
    "labels = ['cloudy', 'partly_cloudy', 'clr']\n",
    "test_df['kavg_condition'] = pd.cut(test_df['k_bar'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Calculate metrics for 'condition'\n",
    "condition_metrics_df = test_df[test_df['is_target']].groupby('condition').apply(calculate_metrics)\n",
    "condition_metrics_df = condition_metrics_df.reindex(['clr', 'partly_cloudy', 'cloudy'], fill_value=np.nan)\n",
    "\n",
    "# Calculate metrics for 'kavg_condition'\n",
    "kavg_condition_metrics_df = test_df[test_df['is_target']].groupby('kavg_condition').apply(calculate_metrics)\n",
    "kavg_condition_metrics_df = kavg_condition_metrics_df.reindex(['clr', 'partly_cloudy', 'cloudy'], fill_value=np.nan)\n",
    "\n",
    "# Print the resulting DataFrames\n",
    "print(\"Metrics for 'ROC condition':\")\n",
    "print(condition_metrics_df)\n",
    "print(\"\\nMetrics for 'kavg_condition':\")\n",
    "print(kavg_condition_metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting MAE and MBE across daily hours (7:00 - 17:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_skycondition(df, condition_spit_sky_condition=\"k_bar\"):\n",
    "    \n",
    "    if condition_spit_sky_condition == 'k_bar':\n",
    "        df['sky_condition'] = df['k_bar'].apply(\n",
    "            lambda x: 'cloudy' if x < 0.6 else ('partly_cloudy' if x < 0.9 else 'clear'))\n",
    "    else :\n",
    "        df['sky_condition'] = df['condition'].apply(\n",
    "            lambda x: 'cloudy' if x == 'cloudy' else ('partly_cloudy' if x == 'partly_cloudy' else 'clear'))\n",
    "\n",
    "    sky_condition_mae = df.groupby('sky_condition')[['I', 'I_LGBM']].apply(lambda x: mean_absolute_error(x['I'], x['I_LGBM'])).reset_index(name='MAE')\n",
    "    sky_condition_rmse = df.groupby('sky_condition')[['I', 'I_LGBM']].apply(lambda x: np.sqrt(mean_squared_error(x['I'], x['I_LGBM']))).reset_index(name='RMSE')\n",
    "        \n",
    "    overall_mae        = mean_absolute_error(df['I'], df['I_LGBM'])\n",
    "    overall_rmse       = np.sqrt(mean_squared_error(df['I'], df['I_LGBM']))\n",
    "    print('Overall MAE [%s]:  %.3f' % (condition_spit_sky_condition, overall_mae))\n",
    "    print('Overall RMSE [%s]: %.3f' % (condition_spit_sky_condition, overall_rmse))\n",
    "    \n",
    "    print('MAE by sky_condition [%s]' % condition_spit_sky_condition)\n",
    "    print(sky_condition_mae)\n",
    "\n",
    "    print('\\nRMSE by sky_condition [%s]' % condition_spit_sky_condition)\n",
    "    print(sky_condition_rmse)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharey='row')\n",
    "    sky_condition_names = ['Clear sky', 'Partly cloudy sky', 'Cloudy sky']\n",
    "\n",
    "    # Define three different color sets for each subplot\n",
    "    color_sets = [['#86A789', '#D2E3C8'], ['#22668D', '#8ECDDD'], ['#2D3250', '#7077A1']]\n",
    "\n",
    "    for i, condition in enumerate(['clear', 'partly_cloudy', 'cloudy']):\n",
    "        filter_test_df = df[df['sky_condition'] == condition]\n",
    "        mae = filter_test_df.groupby('hour')[['I', 'I_LGBM']].apply(\n",
    "            lambda x: mean_absolute_error(x['I'], x['I_LGBM'])).reset_index(name='MAE')\n",
    "        mbe = filter_test_df.groupby('hour')[['I', 'I_LGBM']].apply(lambda x: x['I_LGBM'].mean() - x['I'].mean()).reset_index(\n",
    "            name='MBE')\n",
    "\n",
    "        # Use different color sets for each subplot\n",
    "        bar_colors_mae = [color_sets[i][0] if 10 <= hour <= 15 else color_sets[i][1] for hour in mae['hour']]\n",
    "        bar_colors_mbe = [color_sets[i][0] if 10 <= hour <= 15 else color_sets[i][1] for hour in mbe['hour']]\n",
    "\n",
    "        axes[0, i].bar(mae['hour'], mae['MAE'], color=bar_colors_mae)\n",
    "        axes[0, i].set_title(f'{sky_condition_names[i]} (n={len(filter_test_df)})', fontsize=20)\n",
    "        axes[0, i].set_xlabel('Hour', fontsize=20)\n",
    "        axes[0, i].set_ylabel('MAE [W/sqm]', fontsize=20)\n",
    "\n",
    "        axes[1, i].bar(mbe['hour'], mbe['MBE'], color=bar_colors_mbe)\n",
    "        axes[1, i].set_xlabel('Hour', fontsize=20)\n",
    "        axes[1, i].set_ylabel('MBE [W/sqm]', fontsize=20)\n",
    "         \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "evaluation_skycondition(test_df[test_df['is_target']], condition_spit_sky_condition=\"roc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df = final_train_df.merge(train_df[['sitename', 'Datetime', 'I_LGBM']], on=['sitename', 'Datetime'], how='left')\n",
    "final_train_df = final_train_df.fillna(0)\n",
    "final_val_df   = final_val_df.merge(val_df[['sitename', 'Datetime', 'I_LGBM']], on=['sitename', 'Datetime'], how='left')\n",
    "final_val_df   = final_val_df.fillna(0)\n",
    "final_test_df  = final_test_df.merge(test_df[['sitename', 'Datetime', 'I_LGBM']], on=['sitename', 'Datetime'], how='left')\n",
    "final_test_df  = final_test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_df.to_csv(os.path.join(path_to_save_result, \"train_data_with_lgbm.csv\"), index=False)\n",
    "final_val_df.to_csv(os.path.join(path_to_save_result, \"val_data_with_lgbm.csv\"), index=False)\n",
    "final_test_df.to_csv(os.path.join(path_to_save_result, \"test_data_with_lgbm.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
